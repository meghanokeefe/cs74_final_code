{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Fine-Tune GPT2 Model\n",
    "## This file aims to produce a fine-tuned GPT2 model that can predict Rotton Tomatoes Scores based on movie scripts.\n",
    "### Produced by Meghan O'Keefe, Lily Scott, Daisy Li\n",
    "#### * Please note that ChatGPT itself was used as help to generate the tools to produce this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('modified_all_rt_scores.csv')\n",
    "\n",
    "# Process scripts (grab them from folder and pre-process them)\n",
    "script_texts = []\n",
    "for title in df['IMSDB_Title']:\n",
    "    script_found = False\n",
    "    for folder in ['Saved_Scripts_Raw/scripts-1', 'Saved_Scripts_Raw/scripts-2']:\n",
    "        try:\n",
    "            with open(f'{folder}/{title}.txt', 'r', encoding='utf-8') as file:\n",
    "                script_texts.append(file.read())\n",
    "                script_found = True\n",
    "                break \n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    if not script_found:\n",
    "        script_texts.append(None)\n",
    "        \n",
    "# Eliminate those that are not matched with a script\n",
    "df['Script'] = script_texts\n",
    "df = df.dropna(subset=['Script'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IMSDB_Title</th>\n",
       "      <th>RT_Title</th>\n",
       "      <th>CriticScore</th>\n",
       "      <th>AudienceScore</th>\n",
       "      <th>CriticScoreCategory</th>\n",
       "      <th>Script</th>\n",
       "      <th>CriticScoreLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alien-3</td>\n",
       "      <td>ALIEN-3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\t\\t\\tAlien III\\n\\n\\t\\tScreenplay by John Fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>american-milkshake</td>\n",
       "      <td>MILKSHAKE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>american-werewolf-in-london</td>\n",
       "      <td>AN-AMERICAN-WEREWOLF-IN-LONDON</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n\"An American Werewolf in London\" -- ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>austin-powers---international-man-of-mystery</td>\n",
       "      <td>AUSTIN-POWERS:-INTERNATIONAL-MAN-OF-MYSTERY</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nAustin Powers: International Man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>austin-powers---the-spy-who-shagged-me</td>\n",
       "      <td>AUSTIN-POWERS:-THE-SPY-WHO-SHAGGED-ME</td>\n",
       "      <td>53.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nAUSTIN POWERS: THE SPY WHO SHAGG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1332</td>\n",
       "      <td>Yes-Man</td>\n",
       "      <td>Yes-Man</td>\n",
       "      <td>46.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n           \\n\\n          \\n\\n          \\n\\n ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1333</td>\n",
       "      <td>You-Can-Count-On-Me</td>\n",
       "      <td>You-Can-Count-On-Me</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n                                  \"YOU CAN C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1336</td>\n",
       "      <td>Zero-Dark-Thirty</td>\n",
       "      <td>Zero-Dark-Thirty</td>\n",
       "      <td>91.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n \\n\\n                               ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1337</td>\n",
       "      <td>Zerophilia</td>\n",
       "      <td>Zerophilia</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1338</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>98.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                   IMSDB_Title  \\\n",
       "1              2                                       alien-3   \n",
       "2              4                            american-milkshake   \n",
       "3              6                   american-werewolf-in-london   \n",
       "4             10  austin-powers---international-man-of-mystery   \n",
       "5             11        austin-powers---the-spy-who-shagged-me   \n",
       "...          ...                                           ...   \n",
       "1269        1332                                       Yes-Man   \n",
       "1270        1333                           You-Can-Count-On-Me   \n",
       "1273        1336                              Zero-Dark-Thirty   \n",
       "1274        1337                                    Zerophilia   \n",
       "1275        1338                                      Zootopia   \n",
       "\n",
       "                                         RT_Title  CriticScore  AudienceScore  \\\n",
       "1                                         ALIEN-3         48.0           47.0   \n",
       "2                                       MILKSHAKE          0.0           42.0   \n",
       "3                  AN-AMERICAN-WEREWOLF-IN-LONDON         89.0           85.0   \n",
       "4     AUSTIN-POWERS:-INTERNATIONAL-MAN-OF-MYSTERY         73.0           77.0   \n",
       "5           AUSTIN-POWERS:-THE-SPY-WHO-SHAGGED-ME         53.0           71.0   \n",
       "...                                           ...          ...            ...   \n",
       "1269                                      Yes-Man         46.0           66.0   \n",
       "1270                          You-Can-Count-On-Me         95.0           88.0   \n",
       "1273                             Zero-Dark-Thirty         91.0           80.0   \n",
       "1274                                   Zerophilia         25.0           61.0   \n",
       "1275                                     Zootopia         98.0           92.0   \n",
       "\n",
       "     CriticScoreCategory                                             Script  \\\n",
       "1                 rotten  \\n\\t\\t\\tAlien III\\n\\n\\t\\tScreenplay by John Fa...   \n",
       "2                 rotten  \\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...   \n",
       "3        certified fresh  \\n\\n\\n\\n\\n\"An American Werewolf in London\" -- ...   \n",
       "4                  fresh  \\n\\n\\n\\n\\n\\n\\nAustin Powers: International Man...   \n",
       "5                 rotten  \\n\\n\\n\\n\\n\\n\\nAUSTIN POWERS: THE SPY WHO SHAGG...   \n",
       "...                  ...                                                ...   \n",
       "1269              rotten  \\n           \\n\\n          \\n\\n          \\n\\n ...   \n",
       "1270     certified fresh  \\n                                  \"YOU CAN C...   \n",
       "1273     certified fresh  \\n\\n\\n\\n\\n \\n\\n                               ...   \n",
       "1274              rotten  \\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...   \n",
       "1275     certified fresh  \\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...   \n",
       "\n",
       "      CriticScoreLabel  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    2  \n",
       "4                    1  \n",
       "5                    0  \n",
       "...                ...  \n",
       "1269                 0  \n",
       "1270                 2  \n",
       "1273                 2  \n",
       "1274                 0  \n",
       "1275                 2  \n",
       "\n",
       "[823 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match the categories to class numbers so they are not in string form\n",
    "category_to_label = {\n",
    "    'rotten': 0,\n",
    "    'fresh': 1,\n",
    "    'certified fresh': 2\n",
    "}\n",
    "# Create a new column with the mapped data\n",
    "df['CriticScoreLabel'] = df['CriticScoreCategory'].map(category_to_label)\n",
    "\n",
    "# Split the data into training/testing\n",
    "train_df, eval_df = train_test_split(df, test_size=0.25)\n",
    "\n",
    "# Print the df to check all is in order\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Set the pad token to be the same as the EOS token, since GPT-2 does not have a predefined pad token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the scripts for both training and evaluation sets, similar to tokenizing used in traditional_models.ipynb\n",
    "train_encodings = tokenizer(train_df['Script'].tolist(), truncation=True, padding=True, max_length=1024)\n",
    "eval_encodings = tokenizer(eval_df['Script'].tolist(), truncation=True, padding=True, max_length=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple class that heklps to instantiate datasets to a form that the GPT2 model can understand\n",
    "class ScriptDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ScriptDataset(train_encodings, train_df['CriticScoreLabel'].tolist())\n",
    "eval_dataset = ScriptDataset(eval_encodings, eval_df['CriticScoreLabel'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Explicitly set the padding token in line with already established\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "    \n",
    "# Instantiate model\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=3)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Suggestion to help with processing/computing power issues\n",
    "model.to('cpu')\n",
    "\n",
    "# Define training arguments and continue as before\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                  \n",
    "    num_train_epochs=3,                      \n",
    "    per_device_train_batch_size=1,           \n",
    "    per_device_eval_batch_size=1,            \n",
    "    gradient_accumulation_steps=4,           \n",
    "    warmup_steps=500,                        \n",
    "    weight_decay=0.01,                      \n",
    "    logging_dir='./logs',                    \n",
    "    logging_steps=10,                        \n",
    "    save_strategy='epoch',                   \n",
    "    evaluation_strategy='epoch',             \n",
    "    load_best_model_at_end=True,             \n",
    "    metric_for_best_model='accuracy',        \n",
    "    greater_is_better=False,                 \n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Specify which metric to print and provide\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc}\n",
    "\n",
    "# Add to Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,  # make sure your model is specified here\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model so that it does not have to be trained again!\n",
    "model.save_pretrained('./my_model_directory4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
