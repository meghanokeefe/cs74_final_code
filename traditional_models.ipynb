{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1083808c",
   "metadata": {},
   "source": [
    "# Code to Fine-Tune/Create Traditional Models\n",
    "## This file aims to produce a fine-tuned Logistic Regression, Naive Bayes and Random Forest models that can predict Rotton Tomatoes Scores based on movie scripts.\n",
    "### Produced by Meghan O'Keefe, Lily Scott, Daisy Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc41cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction import text\n",
    "import csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfdc97",
   "metadata": {},
   "source": [
    "# MULTICLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0870c6c",
   "metadata": {},
   "source": [
    "## CLEAN AND VECTORIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbf8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file\n",
    "df = pd.read_csv('modified_all_rt_scores.csv')\n",
    "\n",
    "# Read the scripts in and add to df, discarding those that do not have a correlating script.\n",
    "script_texts = []\n",
    "for title in df['IMSDB_Title']:\n",
    "    script_found = False\n",
    "    for folder in ['Saved_Scripts_Raw/scripts-1', 'Saved_Scripts_Raw/scripts-2']:\n",
    "        try:\n",
    "            with open(f'{folder}/{title}.txt', 'r', encoding='utf-8') as file:\n",
    "                script_texts.append(file.read())\n",
    "                script_found = True\n",
    "                break  \n",
    "        except FileNotFoundError:\n",
    "            continue \n",
    "    if not script_found:\n",
    "        script_texts.append(None)\n",
    "\n",
    "df['Script'] = script_texts\n",
    "\n",
    "# Eliminate Null entries.\n",
    "df = df.dropna(subset=['Script'])\n",
    "\n",
    "# We used several tools to try and optimize our approach: standarizing all text to lowercase, \n",
    "# removing stop words and punctuation, and implementing a stemming approach.\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()  # Stemming\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split() if word not in stop_words])\n",
    "\n",
    "# Pre-process all the scripts to narrow the computational time required\n",
    "df['Processed_Script'] = df['Script'].apply(preprocess_text)\n",
    "\n",
    "# Match the categories to class numbers so they are not in string form\n",
    "category_to_label = {'rotten': 0, 'fresh': 1, 'certified fresh': 2}\n",
    "df['CriticScoreLabel'] = df['CriticScoreCategory'].map(category_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eecd47b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IMSDB_Title</th>\n",
       "      <th>RT_Title</th>\n",
       "      <th>CriticScore</th>\n",
       "      <th>AudienceScore</th>\n",
       "      <th>CriticScoreCategory</th>\n",
       "      <th>Script</th>\n",
       "      <th>Processed_Script</th>\n",
       "      <th>CriticScoreLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>alien-3</td>\n",
       "      <td>ALIEN-3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\t\\t\\tAlien III\\n\\n\\t\\tScreenplay by John Fa...</td>\n",
       "      <td>alien iii screenplay john fasano stori vincent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>american-milkshake</td>\n",
       "      <td>MILKSHAKE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...</td>\n",
       "      <td>american milkshak written david andalman cowri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>american-werewolf-in-london</td>\n",
       "      <td>AN-AMERICAN-WEREWOLF-IN-LONDON</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n\"An American Werewolf in London\" -- ...</td>\n",
       "      <td>american werewolf london john landi fade 1 man...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>austin-powers---international-man-of-mystery</td>\n",
       "      <td>AUSTIN-POWERS:-INTERNATIONAL-MAN-OF-MYSTERY</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nAustin Powers: International Man...</td>\n",
       "      <td>austin power intern man mysteri mike myer aust...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>austin-powers---the-spy-who-shagged-me</td>\n",
       "      <td>AUSTIN-POWERS:-THE-SPY-WHO-SHAGGED-ME</td>\n",
       "      <td>53.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nAUSTIN POWERS: THE SPY WHO SHAGG...</td>\n",
       "      <td>austin power spi shag austin power spi shag mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1332</td>\n",
       "      <td>Yes-Man</td>\n",
       "      <td>Yes-Man</td>\n",
       "      <td>46.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n           \\n\\n          \\n\\n          \\n\\n ...</td>\n",
       "      <td>ye man written nichola stoller base book ye ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1333</td>\n",
       "      <td>You-Can-Count-On-Me</td>\n",
       "      <td>You-Can-Count-On-Me</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n                                  \"YOU CAN C...</td>\n",
       "      <td>count screenplay kenneth lonergan shoot draft ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>1336</td>\n",
       "      <td>Zero-Dark-Thirty</td>\n",
       "      <td>Zero-Dark-Thirty</td>\n",
       "      <td>91.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n \\n\\n                               ...</td>\n",
       "      <td>zero dark thirti written mark boal octob 3rd 2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>1337</td>\n",
       "      <td>Zerophilia</td>\n",
       "      <td>Zerophilia</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>rotten</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...</td>\n",
       "      <td>zerophilia written martin curland revis march ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>1338</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>98.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>certified fresh</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...</td>\n",
       "      <td>zootopia written jare bush phil johnston stori...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                   IMSDB_Title  \\\n",
       "1              2                                       alien-3   \n",
       "2              4                            american-milkshake   \n",
       "3              6                   american-werewolf-in-london   \n",
       "4             10  austin-powers---international-man-of-mystery   \n",
       "5             11        austin-powers---the-spy-who-shagged-me   \n",
       "...          ...                                           ...   \n",
       "1269        1332                                       Yes-Man   \n",
       "1270        1333                           You-Can-Count-On-Me   \n",
       "1273        1336                              Zero-Dark-Thirty   \n",
       "1274        1337                                    Zerophilia   \n",
       "1275        1338                                      Zootopia   \n",
       "\n",
       "                                         RT_Title  CriticScore  AudienceScore  \\\n",
       "1                                         ALIEN-3         48.0           47.0   \n",
       "2                                       MILKSHAKE          0.0           42.0   \n",
       "3                  AN-AMERICAN-WEREWOLF-IN-LONDON         89.0           85.0   \n",
       "4     AUSTIN-POWERS:-INTERNATIONAL-MAN-OF-MYSTERY         73.0           77.0   \n",
       "5           AUSTIN-POWERS:-THE-SPY-WHO-SHAGGED-ME         53.0           71.0   \n",
       "...                                           ...          ...            ...   \n",
       "1269                                      Yes-Man         46.0           66.0   \n",
       "1270                          You-Can-Count-On-Me         95.0           88.0   \n",
       "1273                             Zero-Dark-Thirty         91.0           80.0   \n",
       "1274                                   Zerophilia         25.0           61.0   \n",
       "1275                                     Zootopia         98.0           92.0   \n",
       "\n",
       "     CriticScoreCategory                                             Script  \\\n",
       "1                 rotten  \\n\\t\\t\\tAlien III\\n\\n\\t\\tScreenplay by John Fa...   \n",
       "2                 rotten  \\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...   \n",
       "3        certified fresh  \\n\\n\\n\\n\\n\"An American Werewolf in London\" -- ...   \n",
       "4                  fresh  \\n\\n\\n\\n\\n\\n\\nAustin Powers: International Man...   \n",
       "5                 rotten  \\n\\n\\n\\n\\n\\n\\nAUSTIN POWERS: THE SPY WHO SHAGG...   \n",
       "...                  ...                                                ...   \n",
       "1269              rotten  \\n           \\n\\n          \\n\\n          \\n\\n ...   \n",
       "1270     certified fresh  \\n                                  \"YOU CAN C...   \n",
       "1273     certified fresh  \\n\\n\\n\\n\\n \\n\\n                               ...   \n",
       "1274              rotten  \\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...   \n",
       "1275     certified fresh  \\n\\n\\n\\n\\n\\n\\n\\n\\n                            ...   \n",
       "\n",
       "                                       Processed_Script  CriticScoreLabel  \n",
       "1     alien iii screenplay john fasano stori vincent...                 0  \n",
       "2     american milkshak written david andalman cowri...                 0  \n",
       "3     american werewolf london john landi fade 1 man...                 2  \n",
       "4     austin power intern man mysteri mike myer aust...                 1  \n",
       "5     austin power spi shag austin power spi shag mi...                 0  \n",
       "...                                                 ...               ...  \n",
       "1269  ye man written nichola stoller base book ye ma...                 0  \n",
       "1270  count screenplay kenneth lonergan shoot draft ...                 2  \n",
       "1273  zero dark thirti written mark boal octob 3rd 2...                 2  \n",
       "1274  zerophilia written martin curland revis march ...                 0  \n",
       "1275  zootopia written jare bush phil johnston stori...                 2  \n",
       "\n",
       "[823 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that df has values expected\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51bebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.42      0.47       106\n",
      "           1       0.17      0.12      0.14        40\n",
      "           2       0.54      0.68      0.60       126\n",
      "\n",
      "    accuracy                           0.50       272\n",
      "   macro avg       0.41      0.41      0.40       272\n",
      "weighted avg       0.48      0.50      0.48       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training/testing (X, Y)\n",
    "X = df['Processed_Script']\n",
    "Y = df['CriticScoreLabel']\n",
    "\n",
    "# Found that 0.33 was the most successful split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and choosen model (here we use LogisticRegression, can replace with MultinomialNB or RandomForestClassifier)\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', CountVectorizer(ngram_range=(1,4), min_df = 5)),\n",
    "    ('lr', LogisticRegression(C=0.03359818286283781, max_iter=5000, solver='liblinear', multi_class='ovr'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Create predictions\n",
    "Y_pred = pipeline_rf.predict(X_test)\n",
    "\n",
    "# Evaluation, print classification report\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
